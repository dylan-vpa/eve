"""
AI service using Ollama
"""

import asyncio
import logging
import aiohttp
import json
from typing import Optional
from src.core.config import Config

logger = logging.getLogger(__name__)

class AIService:
    """AI service using Ollama"""
    
    def __init__(self):
        self.host = Config.OLLAMA_HOST
        self.model = Config.OLLAMA_MODEL
        
    async def check_ollama(self) -> bool:
        """Check if Ollama is running"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.host}/api/tags", timeout=5) as response:
                    if response.status == 200:
                        logger.info("‚úÖ Ollama est√° funcionando")
                        return True
                    else:
                        logger.error("‚ùå Ollama no responde correctamente")
                        return False
        except Exception as e:
            logger.error(f"‚ùå Error conectando con Ollama: {e}")
            return False
    
    async def generate_response(self, text: str) -> Optional[str]:
        """Generate AI response using Ollama"""
        try:
            if not await self.check_ollama():
                return None
            
            url = f"{self.host}/api/generate"
            
            data = {
                "model": self.model,
                "prompt": f"Eres un asistente telef√≥nico amigable. Responde de manera natural y √∫til a: {text}",
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_tokens": 150
                }
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        response_text = result.get("response", "").strip()
                        
                        if response_text:
                            logger.info(f"ü§ñ Respuesta AI: {response_text}")
                            return response_text
                        else:
                            logger.warning("‚ö†Ô∏è No se gener√≥ respuesta de AI")
                            return "Lo siento, no pude procesar tu solicitud."
                    else:
                        error_text = await response.text()
                        logger.error(f"‚ùå Error en Ollama API: {response.status} - {error_text}")
                        return "Lo siento, hay un problema t√©cnico."
                        
        except Exception as e:
            logger.error(f"‚ùå Error generando respuesta AI: {e}")
            return "Lo siento, hay un problema t√©cnico."
    
    async def test_connection(self) -> bool:
        """Test Ollama connection"""
        try:
            return await self.check_ollama()
        except Exception as e:
            logger.error(f"‚ùå Error en test de conexi√≥n: {e}")
            return False 